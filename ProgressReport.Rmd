---
title: "ProgressReport"
author: "Caitlin Zimmer"
date: "10/19/2020"
output: html_document
Bibliography: Harborne.ref.bib, Elith.ref.bib
---
For this project I want to recreate the paper by Harborne et al that looks at modeling and mapping the impacts of fishing on coral reefs. I want to specifically recreate Figure 2 which shows the boosted regression tree outcomes for the variables that explained the most variation[@doi:10.1111/ddi.12814]. The data for this paper was easily available, but the code was not provided. I am using R with the package gbm. 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE )
library(tidyverse)
```
My first step of recreating the data analysis from this paper was to download the data. The data was available in an excel file which I converted to a csv file. This led to some issues with column names that I fixed in the code found in the script titled "TidyingData" and rewrote into a new csv (fishdata1). 

Now that I have the data my next step is to gain an understanding of the package used to run boosted regression trees. This package is called gbm (generalized boosted models). I read "A working guide to boosted regression trees" by J. Elith to understand more about the analysis I am going to recreate. This guide was cited in the paper. It includes a tutorial with code and extra functions for completing a BRT[@doi:10.1111/j.1365-2656.2008.01390.x]. 

In this code chunk I will begin following the tutorial mentioned above but applying it to the fish data from the paper. I need to make all the columns with characters into factors. I tried to follow along with the code written with assignment 4 but I get an error when I try to change the export category types into numbers. The code I am using for that did not get an error for protected status, which came above it. If I check what type of object Export Category is, it says "null" while all other columns I changed into factors say "list".

STATUS:Resolved in class with as.numeric function
```{r columns into functions}
fd<-as.data.frame(read_csv("./Data/FishdataRecreating.csv",
             col_types= cols(Protected.status=col_factor(),
                             Export_Category=col_factor(),
                             Geomorphology=col_factor(),
                             Habitat.type=col_factor(),
                             Survey.method=col_factor())))

fd$Protected.status<-as.numeric(fd$Protected.status)
fd$Export_Category<-as.numeric(fd$Export_Category)
fd$Geomorphology<-as.numeric(fd$Geomorphology)
fd$Habitat.type<-as.numeric(fd$Habitat.type)
fd$Survey.method<-as.numeric(fd$Survey.method)
```

To get a better understanding of the data I will first create scatter plots to test out the relationships. 
```{r variable relationships}
ggplot(fd)+
    aes(x=HD_20)+
    aes(y=Mean_length)+
    aes(color=Export_Category)+
    geom_point()+
    geom_smooth(method="lm")+
    xlab("Human Density over 20km")+
    ylab("Mean length of Parrotfish (cm)")

ggplot(fd)+
    aes(x=Tourist20)+
    aes(y=Mean_length)+
    geom_point()+
    geom_smooth(method="lm")+
    xlab("Tourist values over 20km")+
    ylab("Mean length of Parrotfish (cm)")

ggplot(fd)+
    aes(x=Distance_Port)+
    aes(y=Mean_length)+
    geom_point()+
    geom_smooth(method="lm")+
    xlab("Distance from Site to Nearest Port")+
    ylab("Mean length of Parrotfish (cm)")

linearmodel<- lm(fd$Mean_length ~ fd$HD_20)
summary(linearmodel)
linearmodel2<- lm(fd$Mean_length ~ fd$Tourist20)
summary(linearmodel2)
```
From running these tests I see that there is a significant relationship between the density of tourists over 20 kilometers as well as the population density, and the mean length of Parrotfish, with the length decreasing as tourist or human density increases. This is also seen in the scatterplots. 

The paper states in the methods section that all covariates were first tested for coâ€linearity (pairwise r threshold of 0.75), which led to the removal of latitude, tourist pressure and the second axis of socioeconomic development [@doi:10.1111/ddi.12814]. Therefore I will also remove those variables before running the BRT. It also uses a log transformed mean parrot fish size to better fit the Gaussian error distribution. 
```{r correcting data}
newfd<-select(fd, -c(Lat, Tourist20, Tourist200, SED2))
newfd$Mean_length<- log(newfd$Mean_length)
```

Now I am starting to try the BRT
```{r brt}
source("brt.functions.R")
library(gbm)
parrotfish.tc5.lr01 <- gbm.step(data=newfd, 
  gbm.x = c(2:18),
  gbm.y = 1,
  family = "gaussian",
  tree.complexity = 5,
  learning.rate = 0.01,
  bag.fraction = 0.5,
  ZI= FALSE)
# creating a model with my data
#gbm.x is referring to the columns that have predictor variables
#gbm.y is referring to the column with the response variable
# family is the error structure used in the tutorial
#just trying different tree complexities and learning rates until we get a model with enough trees (over 1000)
```
Status:RESOLVED 
When I try to run this it gives me an error saying: Must subset columns with a valid subscript vector. i Logical subscripts must match the size of the indexed input.
Issue was that my data was a tibble not in a data frame. Once I specified data frame the model runs smoothly. I also had to edit the default parameters from the tutorial to match my data. For example, I had to change the family from bernoulli to gaussian and add the line ZI=FALSE because the data is not presence/absence it's numeric observations (length).

Next I retried the model with new learning rates and tree complexities until I got over 1000 trees created. With a learning rate of 0.0045 and a tree complexity of 5 I have 9000 trees.

```{r getting optimal tree number}
parrotfish.tc5.lr0045 <- gbm.step(data=newfd, 
    gbm.x = 2:18,
    gbm.y = 1,
    family = "gaussian",
    tree.complexity = 5,
    learning.rate = 0.0045,
    bag.fraction = 0.5,
    ZI=FALSE)
```

```{r simplyifing model}
fish_simp<- gbm.simplify(parrotfish.tc5.lr0045, n.drops=5) 
```
After running the simplifying function it shows that my model would have the lowest deviance value if I dropped one variable. I will not do this because the tutorial states that when there are many observations it is preferable to include all of your predictive variables even if the simplifier function suggests dropping one. [@doi:10.1111/j.1365-2656.2008.01390.x]

Now I have everything I need to recreate the Figure. To do this I use the gbm.plot function. This creates a plot for the best 8 predictors. I now have the correct plots, but I need to figure out how to label each one like in the paper. I also need to fix my citations because they do not work when I knit the Markdown. 
```{r plotting Figure 2}
par(mfrow=c(2,4))
gbm.plot(parrotfish.tc5.lr0045, n.plots=8, write.title =T )

```

References: